{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d049a7df",
   "metadata": {},
   "source": [
    "# ###############################################################\n",
    "\n",
    "# A general scraper \n",
    "# This code scrapes restaurant data for n webpages, here n is 5.\n",
    "# Each webpage has 15 restaurants, non restaurants in the listing are skipped.\n",
    "# For this particular search, the location is Dubai Marina which can be changed by changing the search_url.\n",
    "\n",
    "# ###############################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9d9118f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importing Libraries \n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import json\n",
    "import pandas as pd\n",
    "from itertools import chain\n",
    "import time\n",
    "\n",
    "# Lists for storing the required data\n",
    "# menu list will be a list of [name, description, price and logo]\n",
    "# example for 1 restaurant, the menu items list will be -\n",
    "# [[name, description, price and logo], [name, description, price and logo],..]\n",
    "restaurant_name = []\n",
    "restaurant_logo = []\n",
    "latitude = []\n",
    "longitude = []\n",
    "cuisine_tags = []\n",
    "menu_items = []\n",
    "\n",
    "# search_link  - the restaurant search results for delivery to a location\n",
    "# here dubai marina or 1272\n",
    "# can be changed to find search results for different delivery locations\n",
    "search_link = \"https://www.talabat.com/uae/restaurants/1272/dubai-marina?page=\"\n",
    "\n",
    "# Base url for parsing restaurant data\n",
    "base_url = \"https://www.talabat.com\"\n",
    "\n",
    "# n is the no of pages to parse\n",
    "# One page has 15 restaurants \n",
    "n = 5\n",
    "\n",
    "# Empty list for storing links\n",
    "links = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33639b10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7.110396862030029 seconds\n"
     ]
    }
   ],
   "source": [
    "# To calculate time of execution for getting hyperlinks from n pages\n",
    "start_time = time.time()\n",
    "\n",
    "# This loop goes page by page to get hyperlinks for different restaurants\n",
    "for i in range(0, n):\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    # Requesting the webpage and loading soup\n",
    "    r = requests.get(search_link + str(i))\n",
    "    soup = BeautifulSoup(r.content,'html.parser')\n",
    "    \n",
    "    # Loop for finding hyperlinks on a single page\n",
    "    for line in soup.find_all('a'):\n",
    "        \n",
    "        temp.append(line.get('href'))\n",
    "    \n",
    "    # Line 22:37 has the links for 15 restaurants\n",
    "    links.append(temp[22:37])\n",
    "\n",
    "# For flattening the list to 1d\n",
    "links = list(chain(*links))\n",
    "\n",
    "# time it took to go through to n pages\n",
    "print(time.time() - start_time, 'seconds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "55e6fa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "119.00781798362732 seconds\n"
     ]
    }
   ],
   "source": [
    "# To calculate the time of execution\n",
    "start_time = time.time()\n",
    "\n",
    "# Loop for parsing required data from restaurant pages in links\n",
    "for i in range(0, len(links)):\n",
    "    \n",
    "    # Requesting individual restaurant webpages and loading soup\n",
    "    r = requests.get(base_url + links[i])\n",
    "    soup = BeautifulSoup(r.content,'html.parser')\n",
    "    \n",
    "    # Extracting data from script \n",
    "    scripts = soup.find('script', type='application/ld+json')\n",
    "    \n",
    "    # Loading to json for easy extraction\n",
    "    data = json.loads(scripts.text)\n",
    "    \n",
    "    # To check if the link is not a restaurant \n",
    "    if (data['@type'] != 'Restaurant'):\n",
    "        \n",
    "        continue\n",
    "        \n",
    "    # Extracting required data (name, logo, coords and tags)\n",
    "    restaurant_name.append( data['name'] )\n",
    "    restaurant_logo.append( data['image'] )\n",
    "    latitude.append( data['geo']['latitude'] )\n",
    "    longitude.append( data['geo']['longitude'] )\n",
    "    cuisine_tags.append( data['servesCuisine'] )\n",
    "    \n",
    "    # Extracting menu data from script\n",
    "    data_menu = soup.find('script', type = 'application/json')\n",
    "    \n",
    "    # Loading to json for easy extraction\n",
    "    data_menu = json.loads(data_menu.text)\n",
    "    \n",
    "    # Extracting required data\n",
    "    menu_list = data_menu['props']['pageProps']['initialMenuState']['menuData']['items']\n",
    "    \n",
    "    temp = []\n",
    "    \n",
    "    # Iterating over menu items to extract required data\n",
    "    for j in range(0, len(menu_list)):\n",
    "\n",
    "        temp.append(\n",
    "            \n",
    "            [menu_list[j]['name'], menu_list[j]['description'], \n",
    "             menu_list[j]['price'], menu_list[j]['image']]\n",
    "            \n",
    "        )\n",
    "        \n",
    "    menu_items.append(temp)\n",
    "    \n",
    "table = {\n",
    "    \n",
    "  \"restaurant_name\": restaurant_name,\n",
    "  \"restaurant_logo\": restaurant_logo,\n",
    "  \"latitude\": latitude,\n",
    "  \"longitude\": longitude,\n",
    "  \"cuisine_tags\": cuisine_tags,\n",
    "  \"menu_items\": menu_items\n",
    "\n",
    "}\n",
    "\n",
    "# time it took\n",
    "print(time.time() - start_time, 'seconds')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f18c6c7c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Converting data to a pandas dataframe \n",
    "df = pd.DataFrame(table) \n",
    "\n",
    "# saving it to a csv file\n",
    "df.to_csv('many_many_restaurants.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
